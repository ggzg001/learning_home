# 操作系统

操作系统位于计算机硬件与应用软件之间，本质也是一个软件。操作系统由操作系统的内核（运行于内核态，管理硬件资源）以及系统调用（运行于用户态，为应用程序员写的应用程序提供系统调用接口）两部分组成，所以，单纯的说操作系统是运行于内核态的，是不准确的。

![1036857-20170118112402265-1697763795](https://ws1.sinaimg.cn/large/006tNc79ly1g2b8h97wo8j30by09wt8v.jpg)

## 操作系统的功能

1. 隐藏了丑陋的硬件调用接口（键盘、鼠标、音箱等等怎么实现的，就不需要你管了），为应用程序员提供调用硬件资源的更好，更简单，更清晰的模型（系统调用接口）。应用程序员有了这些接口后，就不用再考虑操作硬件的细节，专心开发自己的应用程序即可。例如：操作系统提供了文件这个抽象概念，对文件的操作就是对磁盘的操作，有了文件我们无需再去考虑关于磁盘的读写控制（比如控制磁盘转动，移动磁头读写数据等细节）
2. 将应用程序对硬件资源的竞态请求变得有序化。
   例如：很多应用软件其实是共享一套计算机硬件，比方说有可能有三个应用程序同时需要申请打印机来输出内容，那么a程序竞争到了打印机资源就打印，然后可能是b竞争到打印机资源，也可能是c，这就导致了无序，打印机可能打印一段a的内容然后又去打印c...,操作系统的一个功能就是将这种无序变得有序。

## 多道技术

所谓多道程序设计技术，就是指允许多个程序同时进入内存并运行。即同时把多个程序放入内存，并允许它们交替在CPU中运行，它们共享系统中的各种硬、软件资源。当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。

**空间上的复用**：将内存分为几部分，每个部分放入一个程序，这样，同一时间内存中就有了多道程序。

**时间上的复用**：当一个程序在等待I/O时，另一个程序可以使用cpu，如果内存中可以同时存放足够多的作业，则cpu的利用率可以接近100%。

**时间复用上的缺点：**程序员A的程序运行10分钟就能够运行结束，程序员B的程序需要运行24小时，如何程序员B的程序先运行，并且程序员B的程序没有任何I\O操作，那么程序员A需要等待24小时之后才能执行，那么这就不太合理了。

**空间复用上的缺点：**首先丧失的是安全性，比如你的qq程序可以访问操作系统的内存，这意味着你的qq可以拿到操作系统的所有权限。其次丧失的是稳定性，某个程序崩溃时有可能把别的程序的内存也给回收了，比方说把操作系统的内存给回收了，则操作系统崩溃。

解决**空间复用**上的问题：程序之间的内存必须分割，由操作系统控制。如果内存彼此不分割，则一个程序可以访问另外一个程序的内存。
解决**时间复用**:  出现了分时系统.

## 分时系统

把处理机的运行时间分成很短的时间片，按时间片轮流把处理机分配给各联机作业使用。

若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时中断，把处理机让给另一作业使用，等待下一轮时再继续其运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的印象是，好象他独占了一台计算机。而每个用户可以通过自己的终端向系统发出各种操作控制命令，在充分的人机交互情况下，完成作业的运行。

具有上述特征的计算机系统称为分时系统，它允许多个用户同时联机使用计算机。微观上看是各用户轮流使用计算机；宏观上看是各用户并行工作。

## 实时系统

虽然多道批处理系统和分时系统能获得较令人满意的资源利用率和系统响应时间，但却不能满足实时控制与实时信息处理两个应用领域的需求。于是就产生了实时系统，即系统能够及时响应随机发生的外部事件，并在严格的时间范围内完成对该事件的处理。

平常的程序员在日常开发过程中可能接触不到实时系统，正常人谁会去接触导弹或飞机等系统

## 内核态和用户态

内核态和用户态指的是cpu可以操作的指令集的范围。

用户态向内核态转换的情况： 
a.  程序请求操作系统服务， 执行系统调用。 
b.  在程序运行时产生中断事件(如I/O操作完成)，运行程序被中断，转向中断处理程序处理。 
c.  在程序运行时产生异常事件(如在目态下执行特权指令)，运行程序被打断，转向异常处理程序工作。

# 同步、异步、阻塞和非阻塞

## 同步和异步

同步和异步是一组：分清两个概念的关键点是等和不等。

**同步**:一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。其实就是一个程序结束才执行另外一个程序，串行的，不一定两个程序就有依赖关系。
 **异步**：不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。

## 阻塞和非阻塞

阻塞和非阻塞这两个概念与程序（线程）等待消息通知(无所谓同步或者异步)时的状态有关。也就是说阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度来说的。

1. **同步阻塞**：效率最低，编程最简单
2. 异步阻塞：让你不用等了，你还什么事都不做，傻逼。如果在排队取餐的人采用的是异步的方式去等待消息被触发（通知），也就是领了一张小纸条，假如在这段时间里他不能做其它的事情，就在那坐着等着，不能玩游戏等
3. 同步非阻塞：效率低，因为不是异步，没有消息通知机制，需要主动去轮询，把时间浪费在轮询这种不是实事的事情上。想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有，如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的。
4. 异步非阻塞：效率最高。

很多人会把同步和阻塞混淆，是`因为很多时候同步操作会以阻塞的形式表现出来`，同样的，很多人也会把异步和非阻塞混淆，`因为异步操作一般都不会在真正的IO操作处被阻塞`。

# 进程

## 僵尸进程和孤儿进程

### 僵尸进程

僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。

在unix/linux中，正常情况下子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束，如果子进程一结束就立刻回收其全部资源，那么在父进程内将无法获取子进程的状态信息。

因此，UNⅨ提供了一种机制可以保证父进程可以在任意时刻获取子进程结束时的状态信息：

1. 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）
2. 直到父进程通过wait / waitpid来取时才释放. 但这样就导致了问题，如果进程不调用wait / waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。

任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。如果父进程一直存活着，但是却没有进行wait/waitpid的操作，那么就会存在很多僵尸进程危害。

### 孤儿进程

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。<font color="red">孤儿进程是无害的</font>。

孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。

区分僵尸进程和孤儿进程主要还是看子进程和父进程谁先退出。

一般情况下，父进程正常结束之后内部会调用wait / waitpid 去回收僵尸进程，但是如果父进程是一个死循环，永远不会结束，也就永远不会自动去调用wait / waitpid, 那么僵尸进程就会一直存在。僵尸进程过多，就是有害的。有两种解决办法：

1. 杀死父进程，这样僵尸进程就会变为孤儿进程被init回收
2. 对开启的子进程主动调用join, join会回收僵尸进程。

## 进程状态

* 就绪(Ready)状态：当进程已分配到除CPU以外的所有必要的资源，只要获得处理机便可立即执行，这时的进程状态称为就绪状态。
* 执行/运行（Running）状态： 当进程已获得处理机，其程序正在处理机上执行，此时的进程状态称为执行状态。
* 阻塞(Blocked)状态：正在执行的进程，由于等待某个事件发生而无法执行时，便放弃处理机而处于阻塞状态。引起进程阻塞的事件可有多种，例如，等待I/O完成、申请缓冲区不能满足、等待信件(信号)等。

## 进程创建

```python
import time
import os
from multiprocessing import Process

def func():
    print('aaaa')
    time.sleep(1)
    print('子进程>>',os.getpid())
    print('该子进程的父进程>>',os.getppid())
    print(12345)

print('老司机~~~~') #如果我在这里加了一个打印，你会发现运行结果中会出现两次打印出来的老司机，因为我们在主进程中开了一个子进程，子进程中的程序会把主程序的内容拷贝到子进程执行主进程的程序，那么import的时候会不会执行你import的那个文件的程序啊，前面学的，是会执行的，所以出现了两次打印
#其实是因为windows开起进程的机制决定的，在linux下是不存在这个效果的，因为windows使用的是process方法来开启进程，他就会拿到主进程中的所有程序，而linux下只是去执行我子进程中注册的那个函数，不会执行别的程序，这也是为什么在windows下要加上执行程序的时候，
要加上if __name__ == '__main__':，否则会出现子进程中运行的时候还开启子进程，那就出现无限循环的创建进程了，就报错了
```

用pycharm 运行进程程序，会发现主进程的父进程是pycharm；

如果子进程的运行时间长，那么等到子进程执行结束程序才结束，如果主进程的执行时间长，那么主进程执行结束程序才结束，实际上我们在子进程中打印的内容是在主进程的执行结果中看不出来的，但是pycharm帮我们做了优化，因为它会识别到你这是开的子进程，帮你把子进程中打印的内容打印到了显示台上。

### Process类中各方法的介绍

```
p.start()：告诉操作系统可以去调度该进程
p.run(): 立即启动进程，p运行完毕之后再往下执行 
p.terminate():强制终止进程p，不会进行任何清理操作，如果p创建了子进程，该子进程就成了僵尸进程，使用该方法需要特别小心这种情况。如果p还保存了一个锁那么也将不会被释放，进而导致死锁。另外，如果是p.run之后就不能p.terminate()，因为此时p变成None
p.is_alive():如果p仍然运行，返回True
p.join([timeout]):主线程等待p终止（强调：是主线程处于等的状态，而p是处于运行的状态）。timeout是可选的超时时间，需要强调的是，p.join只能join住start开启的进程，而不能join住run开启的进程.
```

### Process类中自带封装的各属性的介绍

```
p.daemon：默认值为False，如果设为True，代表p为后台运行的守护进程，当p的父进程终止时，p也随之终止，并且设定为True后，p不能创建自己的新进程，必须在p.start()之前设置
p.name:进程的名称
p.pid：进程的pid
p.exitcode:进程在运行时为None、如果为–N，表示被信号N结束(了解即可)
```

```python
from multiprocessing import Process
import time
import os
import multiprocessing

def func():
    print(os.getpid(), multiprocessing.current_process().name)
    print(os.getppid())
    time.sleep(2)

if __name__ == '__main__':
    p1 = Process(target=func, name='xx')
    p1.start()
    print('main', p1.is_alive())
```

multiprocessing包本身也有一些方法。

```
class MyProcess(Process):
    def __init__(self, xx):
        # super的init里不能传xx,使用默认参数即可
        super().__init__()
        self.xx = xx

    def run(self):
        print('run', self.name)
        time.sleep(2)


if __name__ == '__main__':
    p1 = MyProcess('xx')
    p1.start()
    print('main', p1.is_alive())
```

<font color="red">子进程开启之后是没法对子进程进行输入操作的，并且没有为子进程input输入提供控制台，所有你再在子进程中写上了input会报错，EOFError错误，这个错误的意思就是你的input需要输入，但是你输入不了，就会报这个错误。而子进程的输出打印之类的，是pycharm做了优化，将所有子进程中的输出结果帮你打印出来了，但实质还是不同进程的。</font>

## 进程同步

进程之间数据不共享,但是共享同一套文件系统,所以访问同一个文件,或同一个打印终端,是没有问题的，而共享带来的是竞争，竞争带来的结果就是错乱，如何控制，就是加锁处理。

### 锁

```python
import json
import time

from multiprocessing import Process
"""tickets
{"num": 1}
"""

def get_ticket(i):
    with open("tickets") as f:
        data = json.load(f)
    if data["num"] > 0:
        print(f"{i}抢到票啦")
        data["num"] -= 1
        time.sleep(0.2)
        with open("tickets", "w") as f:
            json.dump(data, f)
    else:
        print(f"{i}没抢到票，票没啦")

if __name__ == '__main__':
    for i in range(10):
        p = Process(target=get_ticket, args=(i,))
        p.start()
```

tickets中明明只有一张票，在现实中应该只能被一个人抢到，但是在我们的程序中，有10个人都抢到，这明显不合理，代码有问题，需要加锁。

### 队列

站在应用开发者的角度，我们不想自己加锁(什么时候加，加在哪都是问题)，有没有一种方式可以不用加锁而且能共享进程数据(非文件共享方式)，要是有牛逼的人做了这两件事就好了，还他妈真有。

queue常用方法：

```
q = Queue([maxsize]) 
创建共享的进程队列。maxsize是队列中允许的最大项数。如果省略此参数，则无大小限制。底层队列使用管道和锁定实现。另外，还需要运行支持线程以便队列中的数据传输到底层管道中。 
Queue的实例q具有以下方法：

q.get( [ block [ ,timeout ] ] ) 
返回q中的一个项目。如果q为空，此方法将阻塞，直到队列中有项目可用为止。block用于控制阻塞行为，默认为True. 如果设置为False，将引发Queue.Empty异常（定义在Queue模块中）。timeout是可选超时时间，用在阻塞模式中。如果在制定的时间间隔内没有项目变为可用，将引发Queue.Empty异常。

q.get_nowait( ) 
同q.get(False)方法。

q.put(item [, block [,timeout ] ] ) 
将item放入队列。如果队列已满，此方法将阻塞至有空间可用为止。block控制阻塞行为，默认为True。如果设置为False，将引发Queue.Empty异常（定义在Queue库模块中）。timeout指定在阻塞模式中等待可用空间的时间长短。超时后将引发Queue.Full异常。

q.qsize() 
返回队列中目前项目的正确数量。此函数的结果并不可靠，因为在返回结果和在稍后程序中使用结果之间，队列中可能添加或删除了项目。在某些系统上，此方法可能引发NotImplementedError异常。


q.empty() 
如果调用此方法时 q为空，返回True。如果其他进程或线程正在往队列中添加项目，结果是不可靠的。也就是说，在返回和使用结果之间，队列中可能已经加入新的项目。

q.full() 
如果q已满，返回为True. 由于线程的存在，结果也可能是不可靠的（参考q.empty（）方法）。。

```

#### 生产者消费者模型

生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力，并且我<font color="red">可以根据生产速度和消费速度来均衡一下多少个生产者可以为多少个消费者提供足够的服务</font>，就可以开多进程等等，而这些进程都是到阻塞队列或者说是缓冲区中去获取或者添加数据。

```python
# import time
# import random
#
# from termcolor import colored
# from multiprocessing import Process, Queue
#
#
# def produce(q):
#     for i in range(10):
#         time.sleep(random.random())
#         q.put(i)
#         print(colored(f"生产者生产数据{i}", "green"))
#
# def consume(q):
#     while True:
#         data = q.get()
#         time.sleep(random.random())
#         print(colored(f"消费者拿到数据{data}", "blue"))
#
#
# if __name__ == '__main__':
#     q = Queue(maxsize=10)
#     producer = Process(target=produce, args=(q, ))
#     producer.start()
#     consumer = Process(target=consume, args=(q, ))
#     consumer.start()
#

import time
import random

from termcolor import colored
from multiprocessing import Process, JoinableQueue


def produce(q):
    for i in range(10):
        time.sleep(random.random())
        q.put(i)
        print(colored(f"生产者生产数据{i}", "green"))
    q.join()

def consume(q):
    while True:
        data = q.get()
        time.sleep(random.random())
        print(colored(f"消费者拿到数据{data}", "blue"))
        q.task_done()


if __name__ == '__main__':
    q = JoinableQueue(maxsize=10)
    producer = Process(target=produce, args=(q, ))
    producer.start()
    consumer = Process(target=consume, args=(q, ))
    consumer.daemon = True
    consumer.start()
    producer.join()
```

### 信号量

```python
import time

from multiprocessing import Semaphore, Process

def get_bed(sem, i):
    sem.acquire()
    print(f"{i}抢到床睡觉")
    time.sleep(2)
    sem.release()

if __name__ == '__main__':
    sem = Semaphore(3)
    for i in range(10):
        p = Process(target=get_bed, args=(sem, i))
        p.start()
```

## 进程池

**创建进程池的类：如果指定numprocess为3，则进程池会从无到有创建三个进程，然后自始至终使用这三个进程去执行所有任务（高级一些的进程池可以根据你的并发量，搞成动态增加或减少进程池中的进程数量的操作），不会开启其他进程，提高操作系统效率，减少空间的占用等。**

```python
# import time
# from multiprocessing import Pool
#
# def func():
#     print('func')
#     time.sleep(0.2)
#
# if __name__ == '__main__':
#     pool = Pool(3)
#     for i in range(10):
#         pool.apply(func)
#     print("over...")

# import time
# from multiprocessing import Pool
#
# def func(i):
#     print('func')
#     time.sleep(0.2)
#     return i
#
# if __name__ == '__main__':
#     pool = Pool(3)
#     result_list = []
#     for i in range(10):
#         res = pool.apply_async(func, args=(i, ))
#         result_list.append(res)
    # 如果没有pool下面的两行操作，那么取结果的get是阻塞的
    #pool.close()  # 不是关闭进程池，而是结束进程池接收任务，确保没有新任务再提交过来。
    #pool.join()  # 感知进程池中的任务已经执行结束，只有当没有新的任务添加进来的时候，才能感知到任务结束了，所以在join之前必须加上close方法
#     for res in result_list:
#         print(res.get())
#     print("over...")

import time
from multiprocessing import Pool

def func(i):
    print('func')
    time.sleep(0.2)
    return i

if __name__ == '__main__':
    pool = Pool(3)
    result_list = []
    res = pool.map(func, range(10))
    print(res)
    print("over...")
```

map函数只能处理func只接收一个参数的函数(当然你可以使用偏函数进行包装)。另外map集成了close和join的功能，所以map返回值就是值列表，另外map无法像apply_async使用callback，因为没必须要，既然已经把所有结果一并拿到就没必要进行回调了。

### 回调函数的应用场景

进程池中任何一个任务一旦处理完了，就立即告知主进程：我好了额，你可以处理我的结果了。主进程则调用一个函数去处理该结果，该函数即回调函数，这是进程池特有的，普通进程没有这个机制，但是我们也可以通过进程通信来拿到返回值，进程池的这个回调也是进程通信的机制完成的。

我们可以把耗时间（阻塞）的任务放到进程池中，然后指定回调函数（主进程负责执行），这样主进程在执行回调函数时就省去了I/O的过程，直接拿到的是任务的结果。

回调函数在写的时候注意一点，回调函数的形参执行有一个，如果你的执行函数有多个返回值，那么也可以被回调函数的这一个形参接收，接收的是一个元祖，包含着你执行函数的所有返回值。另外，还有一点值得说明的是：**如果在主进程中等待进程池中所有任务都执行完毕后，再统一处理结果，则无需回调函数**。

## 进程共享

进程没有任何共享状态，进程修改的数据，改动仅限于该进程内，但是通过一些特殊的方法，可以实现进程之间数据的共享。

## 